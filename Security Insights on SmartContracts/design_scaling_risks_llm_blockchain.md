# ğŸ§  Smart Contract Explainability Tool

## ğŸ§© Design Tradeoffs

- **Model choice:** We use `gpt-4o-mini` for cost-effective reasoning. While `gpt-4` provides more accurate results, itâ€™s slower and costlier. GPT-4 (original) has a lower token limit than GPT-4o and its variants including GPT-4o-mini(10k token limit).
- **Security vs. Speed:** LLM responses are safeguarded with guardrails in prompts to avoid code generation or security leaks. This slightly slows down output generation but improves safety.
- **ABI fallback:** When source code is unavailable, the tool explains contracts using only the ABI â€” trading off depth for broader applicability.

---

## ğŸ“ˆ Scaling the Prototype

- **Caching:** Add memoization or Redis to avoid re-processing identical contracts.
- **On-chain/off-chain separation:**
  - **On-chain:** ABI, bytecode, and metadata live on-chain (retrieved via Etherscan/Web3).
  - **Off-chain:** The LLM inference, formatting, and explainability are off-chain â€” ideal for maintaining cost and speed efficiency.
- **Queue/Async processing:** Add background task queues (e.g., Celery + Redis) to manage long-running LLM calls.

---

## âš ï¸ Risks of LLM-Generated Code in Blockchain

- **Overtrust in summaries:** Users might falsely assume the contract is safe if the LLM doesn't detect edge-case vulnerabilities.
- **LLM hallucinations:** Fabricated functions or incorrect logic interpretation could mislead users.
- **No real auditing:** This tool is not a substitute for formal verification or human auditing.
- **Security impact:** LLMs should never suggest or generate Solidity code without context or controls â€” we strictly avoid code generation.

---

# ğŸ§  Smart Contract Explainer â€“ Summary

A tool that takes Sepolia testnet contract addresses or Solidity code and uses `web3.py`, Etherscan, and OpenAI (GPT-4o-mini) to generate plain-English summaries explaining key functions, permissions, and security aspects.
